{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3281311",
   "metadata": {},
   "source": [
    "https://pythonhosted.org/jupyter_runner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74429669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cachedDirPath = \"./cached/\"\n",
    "if os.environ.get('RCT_MOCKDATA_GENERATOR_DEL_CACHE') == 'true':\n",
    "    os.system(\"rm -rf cached >/dev/null 2>&1\")\n",
    "os.system(\"mkdir -p cached >/dev/null 2>&1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997ee8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCT_USER = os.environ.get('RCT_USER')\n",
    "RCT_PASSWORD = os.environ.get('RCT_PASSWORD')\n",
    "RCT_DATABASE = os.environ.get('RCT_DATABASE')\n",
    "RCT_DATABASE_HOST = os.environ.get('RCT_DATABASE_HOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6af8fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(sys.executable + \" -m pip install pandas\")\n",
    "os.system(sys.executable + \" -m pip install numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e73326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from numpy.random import randint, uniform, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a674d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_rand_letter = lambda: chr(np.random.randint(ord('a'), ord('z')))\n",
    "gen_rand_char = lambda: chr(np.random.randint(ord('a'), ord('z')))\n",
    "gen_rand_string = lambda n: ''.join([gen_rand_char() for _ in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc9f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating tables\n"
     ]
    }
   ],
   "source": [
    "print(\"creating tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6384de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf147c1",
   "metadata": {},
   "source": [
    "# Beam directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844878b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>beam_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PbPb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pPb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>np</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id beam_type\n",
       "0   0      PbPb\n",
       "1   1        pp\n",
       "2   2       pPb\n",
       "3   3        nn\n",
       "4   4        np"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_beams_dictionary_df_path = cachedDirPath + \"beams_dictionary_df\"\n",
    "\n",
    "beams_types = ['PbPb', 'pp', 'pPb', 'nn', 'np']\n",
    "beams_dictionary = [(i, bt) for i, bt in enumerate(beams_types)]\n",
    "\n",
    "if not os.path.exists(cached_beams_dictionary_df_path):\n",
    "    beams_dictionary_df = pd.DataFrame(beams_dictionary)\n",
    "    beams_dictionary_df.rename(columns=\n",
    "                                    {0:'id',\n",
    "                                    1:'beam_type',\n",
    "                                    }, inplace=True)\n",
    "    beams_dictionary_df.to_csv(cached_beams_dictionary_df_path)\n",
    "else:\n",
    "    beams_dictionary_df = read_csv(cached_beams_dictionary_df_path)\n",
    "\n",
    "beams_dictionary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caedcbd",
   "metadata": {},
   "source": [
    "# Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95a00ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>beam_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LHC10b</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LHC10i</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LHC10w</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LHC10x</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LHC10y</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LHC11b</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>LHC11d</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LHC11f</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LHC11g</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LHC11h</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  year  beam_type_id\n",
       "0   0  LHC10b  2010             1\n",
       "1   1  LHC10i  2010             4\n",
       "2   2  LHC10w  2010             0\n",
       "3   3  LHC10x  2010             1\n",
       "4   4  LHC10y  2010             0\n",
       "5   5  LHC11b  2011             2\n",
       "6   6  LHC11d  2011             4\n",
       "7   7  LHC11f  2011             3\n",
       "8   8  LHC11g  2011             1\n",
       "9   9  LHC11h  2011             2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_periods_df_path = cachedDirPath + \"periods_df\"\n",
    "\n",
    "size = 50\n",
    "years = [str(y) for y in range(2010, 2020)]\n",
    "periods_names = np.unique([f'LHC{choice(years)}{gen_rand_letter()}' for i in range(size)])\n",
    "beams_types_id = [randint(0, len(beams_types)) for _ in range(len(periods_names))]\n",
    "\n",
    "if not os.path.exists(cached_periods_df_path):\n",
    "    periods = [(i, n[:3] + n[5:], int(n[3:7]), t) for (i, (n, t)) in enumerate(zip(periods_names, beams_types_id))]\n",
    "    periods_df = pd.DataFrame(periods)\n",
    "    periods_df.rename(columns=\n",
    "                            {0: 'id',\n",
    "                            1: 'name',\n",
    "                            2: 'year',\n",
    "                            3: 'beam_type_id'}, inplace=True)\n",
    "    periods_df.to_csv(cached_periods_df_path)\n",
    "else:\n",
    "    periods_df = read_csv(cached_periods_df_path)\n",
    "\n",
    "periods_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cfea0",
   "metadata": {},
   "source": [
    "# Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_B_field = lambda: f'{choice([\"+\", \"-\"])}{uniform(0, 2):.7} T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df22ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_runs_df_path = cachedDirPath + \"runs_df\"\n",
    "\n",
    "if not os.path.exists(cached_runs_df_path):\n",
    "    runs = [np.unique(randint(\n",
    "                                    pi*1000,\n",
    "                                    (pi+1)*1000,\n",
    "                                    np.random.randint(50, 200)))\n",
    "                    for pi in range(len(periods_names))]\n",
    "    runTypes = ['technical', 'data', 'cosmic', 'callibration', 'sim']\n",
    "    energyForPeriodsRuns = dict([(i, randint(500, 1500)) for i in range(len(periods_names))])\n",
    "    runs_df = pd.DataFrame([\n",
    "                        (\n",
    "                      -1, \n",
    "                      pi,\n",
    "                      run_number,\n",
    "                      randint(1000, 10000),\n",
    "                      randint(10000, 100000),\n",
    "                      gen_B_field(),\n",
    "                      energyForPeriodsRuns[pi],\n",
    "                      f'IR-{gen_rand_string(5)}',\n",
    "                      randint(12345, 23456), \n",
    "                      f'trigg_conf-{gen_rand_string(5)}', \n",
    "                      randint(123456, 234567), \n",
    "                      choice(runTypes),\n",
    "                      f'mu-{gen_rand_string(6)}', \n",
    "                      randint(1000000000000,5999999999999), \n",
    "                      randint(6000000000000,9999999999999)\n",
    "                    ) for pi, runs in enumerate(runs)\n",
    "                        for run_number in runs\n",
    "                    ])\n",
    "\n",
    "    runs_df.rename(columns=\n",
    "                            {0: 'id',\n",
    "                            1: 'period_id',\n",
    "                            2: 'run_number',\n",
    "                            3: 'start',\n",
    "                            4: 'end',\n",
    "                            5: 'B_field',\n",
    "                            6: 'energy_per_beam',\n",
    "                            7: 'IR',\n",
    "                            8: 'filling_scheme',\n",
    "                            9: 'triggers_conf',\n",
    "                            10: 'fill_number',\n",
    "                            11: 'runType',\n",
    "                            12: 'mu',\n",
    "                            13: 'timeTrgStart',\n",
    "                            14: 'timeTrgEnd'}, inplace=True)\n",
    "    runs_df['id'] = pd.Series(range(0, len(runs_df)))\n",
    "    \n",
    "    runs_df.to_csv(cached_runs_df_path)\n",
    "else:\n",
    "    runs_df = read_csv(cached_runs_df_path)\n",
    "  \n",
    "runs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93574646",
   "metadata": {},
   "source": [
    "# Data Passess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a23419",
   "metadata": {},
   "source": [
    "### pass_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_pass_types_df_path = cachedDirPath + \"pass_types_df\"\n",
    "\n",
    "if not os.path.exists(cached_pass_types_df_path):\n",
    "    pass_types = ['technical', 'data', 'calibration']\n",
    "    pass_types = [(i, bt) for i, bt in enumerate(pass_types)]\n",
    "    pass_types_df = pd.DataFrame(pass_types)\n",
    "    pass_types_df.rename(columns=\n",
    "                                    {0:'id',\n",
    "                                    1:'pass_type',\n",
    "                                    }, inplace=True)\n",
    "\n",
    "    pass_types_df.to_csv(cached_pass_types_df_path)\n",
    "else:\n",
    "    pass_types_df = read_csv(cached_pass_types_df_path)\n",
    "    \n",
    "pass_types_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a34613",
   "metadata": {},
   "source": [
    "### data_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_data_passes_df_path = cachedDirPath + \"data_passes_df\"\n",
    "\n",
    "\n",
    "if not os.path.exists(cached_data_passes_df_path):\n",
    "    data_passes_names = [choice(periods_names) + '__' + gen_rand_string(10) for _ in range(150)]\n",
    "    data_passes_df = pd.DataFrame([\n",
    "        (i,\n",
    "        n, \n",
    "        choice(['dec', '']), \n",
    "        randint(0, len(pass_types)),\n",
    "        choice(['jira-', '']),\n",
    "        choice(['ML-', '']),\n",
    "        randint(10, 100), \n",
    "        f'sof-v.{randint(5)}.{randint(5)}-{gen_rand_string(2)}',\n",
    "        123456\n",
    "        ) for i, n in enumerate(data_passes_names)\n",
    "    ])\n",
    "    data_passes_df.rename(columns={\n",
    "        0: 'id',\n",
    "        1: 'name',\n",
    "        2: 'description',\n",
    "        3: 'pass_type',\n",
    "        4: 'jira',\n",
    "        5: 'ML',\n",
    "        6: 'number_of_events',\n",
    "        7: 'software_version',\n",
    "        8: 'size'\n",
    "    }, inplace=True)\n",
    "\n",
    "    data_passes_df.to_csv(cached_data_passes_df_path)\n",
    "else:\n",
    "    data_passes_df = read_csv(cached_data_passes_df_path)\n",
    "\n",
    "data_passes_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09100693",
   "metadata": {},
   "source": [
    "### data_passes_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_data_passes_runs_path = cachedDirPath + \"data_passes_runs\"\n",
    "\n",
    "if not os.path.exists(cached_data_passes_runs_path):\n",
    "    data_passes_runs = [runs_df['id'].sample(n=randint(10, 100), replace=False).unique()\n",
    "                        for an in range(len(data_passes_df))]\n",
    "    data_passes_runs_df = pd.DataFrame([\n",
    "        (-1,\n",
    "        prod_id,\n",
    "        run_id\n",
    "        )\n",
    "        for prod_id, rs in enumerate(data_passes_runs)\n",
    "            for run_id in rs\n",
    "    ])\n",
    "    data_passes_runs_df.rename(columns=\n",
    "                            {0: 'id',\n",
    "                                1: 'production_id',\n",
    "                                2: 'run_id'\n",
    "                            }, inplace=True)\n",
    "    data_passes_runs_df['id'] = pd.Series(range(len(data_passes_runs_df)))\n",
    "\n",
    "    data_passes_runs_df.to_csv(cached_data_passes_runs_path)\n",
    "else:\n",
    "    data_passes_runs_df = read_csv(cached_data_passes_runs_path)\n",
    "\n",
    "data_passes_runs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239374c",
   "metadata": {},
   "source": [
    "# Sim passes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544a047",
   "metadata": {},
   "source": [
    "### simulation_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cached_simulation_passes_df_path = cachedDirPath + \"simulation_passes_df\"\n",
    "\n",
    "if not os.path.exists(cached_simulation_passes_df_path):\n",
    "    simulation_passes_names = [choice(periods_names) + '__' + gen_rand_string(10) for _ in range(150)]\n",
    "    simulation_passes_df = pd.DataFrame([\n",
    "        (i,\n",
    "        n, \n",
    "        choice(['dec', '']), \n",
    "        choice(['jira-??', '']),\n",
    "        choice(['ML-??', '']),\n",
    "        f'PWG-{gen_rand_string(10)}', \n",
    "        randint(10, 100)\n",
    "        ) for i, n in enumerate(simulation_passes_names)\n",
    "    ])\n",
    "    simulation_passes_df.rename(columns={\n",
    "        0: 'id',\n",
    "        1: 'name',\n",
    "        2: 'description',\n",
    "        3: 'jira',\n",
    "        4: 'ML',\n",
    "        5: 'PWG',\n",
    "        6: 'number_of_events'\n",
    "    }, inplace=True)\n",
    "\n",
    "    simulation_passes_df.to_csv(cached_simulation_passes_df_path)\n",
    "else:\n",
    "    simulation_passes_df = read_csv(cached_simulation_passes_df_path)\n",
    "\n",
    "simulation_passes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f74a23",
   "metadata": {},
   "source": [
    "### simulation_passes_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_simulation_passes_runs_path = cachedDirPath + \"simulation_passes_runs\"\n",
    "\n",
    "if not os.path.exists(cached_simulation_passes_runs_path):\n",
    "    simulation_passes_runs = [runs_df['id']\n",
    "                            .sample(n=randint(10, 100), replace=False)\n",
    "                            .unique() for an in range(len(simulation_passes_df))\n",
    "                            ]\n",
    "    simulation_passes_runs_df = pd.DataFrame([\n",
    "        (-1,\n",
    "        prod_id,\n",
    "        run_id\n",
    "        )\n",
    "        for prod_id, rs in enumerate(simulation_passes_runs)\n",
    "            for run_id in rs\n",
    "    ])\n",
    "    simulation_passes_runs_df.rename(columns=\n",
    "                            {0: 'id',\n",
    "                                1: 'simulation_pass_id',\n",
    "                                2: 'run_id'\n",
    "                            }, inplace=True)\n",
    "    simulation_passes_runs_df['id'] = pd.Series(range(len(simulation_passes_runs_df)))\n",
    "\n",
    "    simulation_passes_runs_df.to_csv(cached_simulation_passes_runs_path)\n",
    "else:\n",
    "    simulation_passes_runs_df = read_csv(cached_simulation_passes_runs_path)\n",
    "simulation_passes_runs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25a231",
   "metadata": {},
   "source": [
    "### detectors_subsystems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_detectors_subsystems_df_path = cachedDirPath + \"detectors_subsystems_df\"\n",
    "\n",
    "if not os.path.exists(cached_detectors_subsystems_df_path):\n",
    "    detectors_names = ['CPV', 'EMC', 'FDD', 'FT0', 'FV0', 'HMP', 'ITS', 'MCH', 'MFT', 'MID', 'PHS', 'TOF', 'TPC', 'TRD', 'ZDC']\n",
    "    detectors_subsystems = [(i, n) for i, n in enumerate(detectors_names)]\n",
    "    detectors_subsystems_df = pd.DataFrame(detectors_subsystems)\n",
    "    detectors_subsystems_df.rename(columns=\n",
    "                                {0: 'id',\n",
    "                                    1: 'name'}, inplace=True)\n",
    "\n",
    "\n",
    "    detectors_subsystems_df.to_csv(cached_detectors_subsystems_df_path)\n",
    "else:\n",
    "    detectors_subsystems_df = read_csv(cached_detectors_subsystems_df_path)\n",
    "\n",
    "detectors_subsystems_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846fd98",
   "metadata": {},
   "source": [
    "### runs_detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_runs_detectors_df_path = cachedDirPath + \"runs_detectors_df\"\n",
    "\n",
    "if not os.path.exists(cached_runs_detectors_df_path):\n",
    "    runs_detectors = [(\n",
    "                    run_id, \n",
    "                    choice(list(range(len(detectors_subsystems_df))),\n",
    "                            replace=False,\n",
    "                            size=randint(1, len(detectors_subsystems_df)))\n",
    "                    ) for run_id in range(len(runs_df))]\n",
    "    runs_detectors_df = pd.DataFrame([(-1,\n",
    "                                    run_id,\n",
    "                                    detector_id)\n",
    "                                    for run_id, an in runs_detectors\n",
    "                                        for detector_id in an\n",
    "                                    ])\n",
    "    runs_detectors_df.rename(columns={\n",
    "        0: 'id',\n",
    "        1: 'run_id',\n",
    "        2: 'detector_id'}, inplace=True)\n",
    "    runs_detectors_df['id'] = pd.Series(range(len(runs_detectors_df)))\n",
    "\n",
    "\n",
    "    runs_detectors_df.to_csv(cached_runs_detectors_df_path)\n",
    "else:\n",
    "    runs_detectors_df = read_csv(cached_runs_detectors_df_path)\n",
    "\n",
    "runs_detectors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943cf75",
   "metadata": {},
   "source": [
    "### flags_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_flags_dictionary_df_path = cachedDirPath + \"flags_dictionary_df\"\n",
    "\n",
    "if not os.path.exists(cached_flags_dictionary_df_path):\n",
    "    flags = ['ok', 'good', 'noise', 'dist', 'harm', 'chaotic', 'clear', 'heh']\n",
    "    flags_dictionary = [(i, f) for i, f in enumerate(flags)]\n",
    "    flags_dictionary_df = pd.DataFrame(flags_dictionary)\n",
    "    flags_dictionary_df.rename(columns={0: 'id', 1: 'flag'}, inplace=True)\n",
    "\n",
    "    flags_dictionary_df.to_csv(cached_flags_dictionary_df_path)\n",
    "else:\n",
    "    flags_dictionary_df = read_csv(cached_flags_dictionary_df_path)\n",
    "flags_dictionary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b1250",
   "metadata": {},
   "source": [
    "### quality_control_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344305e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cached_quality_control_flags_df_path = cachedDirPath + \"quality_control_flags_df\"\n",
    "\n",
    "if not os.path.exists(cached_quality_control_flags_df_path):\n",
    "    quality_control_flags_df = pd.merge(data_passes_runs_df.rename(columns={'id':'pass_run_id'}),\n",
    "                                runs_detectors_df.rename(columns={'id':'run_detector_id'}),\n",
    "                                how='inner',\n",
    "                                on='run_id')\n",
    "    quality_control_flags_df.drop(columns=['production_id', 'detector_id', 'run_id'], inplace=True)\n",
    "    quality_control_flags_df['start'] = pd.Series([randint(1000000, 5999999)\n",
    "                                            for _ in range(len(quality_control_flags_df))])\n",
    "    quality_control_flags_df['end'] = pd.Series([randint(6000000, 9999999)\n",
    "                                            for _ in range(len(quality_control_flags_df))])\n",
    "\n",
    "    quality_control_flags_df['flag_type_id'] = pd.Series([flags_dictionary_df['id'].sample().iloc[0]\n",
    "                                                    for _ in range(len(quality_control_flags_df))])\n",
    "\n",
    "    quality_control_flags_df['id'] = pd.Series(range(len(quality_control_flags_df)))\n",
    "    quality_control_flags_df['comment'] = pd.Series([choice(['', 'cc'], p=[0.6, 0.4])\n",
    "                                                    for _ in range(len(quality_control_flags_df))])\n",
    "\n",
    "\n",
    "    quality_control_flags_df.to_csv(cached_quality_control_flags_df_path)\n",
    "else:\n",
    "    quality_control_flags_df = read_csv(cached_quality_control_flags_df_path)\n",
    "    \n",
    "quality_control_flags_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cfdfe",
   "metadata": {},
   "source": [
    "# Inserting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(sys.executable + \" -m pip install psycopg2-binary\")\n",
    "import psycopg2 as pypg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pypg.connect(host=RCT_DATABASE_HOST,\n",
    "                          user=RCT_USER,\n",
    "                          dbname=RCT_DATABASE,\n",
    "                          password=RCT_PASSWORD)\n",
    "cur = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98887508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def isfloat(s):\n",
    "    b = True\n",
    "    try:\n",
    "        float(s)\n",
    "    except Exception as e:\n",
    "        b = False\n",
    "    return b\n",
    "\n",
    "def insert_row(row, targetTableName, counter, logExceptions, logstep=1000):\n",
    "    selectors_stm = \"(\\\"id\\\", \\\"\" + \"\\\", \\\"\".join(row.index) + \"\\\")\"\n",
    "    values = [str(a) for a in row]\n",
    "    values_list = \"(DEFAULT, \" + \", \".join([s if isfloat(s) else f\"\\'{s}\\'\" for s in values])+ \")\"\n",
    "\n",
    "    command = f\"INSERT INTO {targetTableName} {selectors_stm} VALUES {values_list}\"\n",
    "    try:\n",
    "        cur.execute(command)\n",
    "        connection.commit()\n",
    "        counter[0] += 1\n",
    "    except Exception as e:\n",
    "        if logExceptions:\n",
    "            print('')\n",
    "            print(e)\n",
    "            print(f'inserting to table {targetTableName} {counter}', end='\\x1b\\r')\n",
    "        connection.rollback()       \n",
    "    counter[1] += 1\n",
    "    if counter[0] % logstep:\n",
    "        print(f'inserting to table {targetTableName} {counter}', end='\\x1b\\r')\n",
    "        \n",
    "def insert_table_row_by_row(df: pd.DataFrame, targetTableName: str, logExceptions=True):\n",
    "    counter = [0, 0]\n",
    "    print(f'inserting to table {targetTableName} {counter}', end='\\x1b\\r')\n",
    "    df.drop(columns=['id']).apply(lambda r:\n",
    "                                      insert_row(r, targetTableName, counter, logExceptions),\n",
    "                                  axis=1)\n",
    "    print(f'inserting to table {targetTableName} {counter}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690beb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablesAndNames = [(beams_dictionary_df, 'beams_dictionary'),\n",
    "                  (periods_df, 'periods'),\n",
    "                  \n",
    "                  (runs_df, 'runs'),\n",
    "                  \n",
    "                  (pass_types_df, 'pass_types'),\n",
    "                  (data_passes_df, 'data_passes'),\n",
    "                  (data_passes_runs_df, 'data_passes_runs'),\n",
    "                  \n",
    "                  (simulation_passes_df, 'simulation_passes'),\n",
    "                  (simulation_passes_runs_df, 'simulation_passes_runs'),\n",
    "                  \n",
    "                  (detectors_subsystems_df, 'detectors_subsystems'),\n",
    "                  (runs_detectors_df, 'runs_detectors'),\n",
    "                  \n",
    "                  (flags_dictionary_df, 'flags_types_dictionary'),\n",
    "                  (quality_control_flags_df, 'quality_control_flags')\n",
    "                 ]\n",
    "\n",
    "for (t, n) in tablesAndNames:\n",
    "    print(f'inserting table {n}')\n",
    "    insert_table_row_by_row(t, n, logExceptions=False)\n",
    "    print(f'table {n} inserted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba9a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
